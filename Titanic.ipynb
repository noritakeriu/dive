{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【課題】タイタニック生存予測　ランダムフォレスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ取得・読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248706</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fynney, Mr. Joseph J</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239865</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248698</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>D56</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330923</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113788</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Miss. Torborg Danira</td>\n",
       "      <td>female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347077</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2631</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330959</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Todoroff, Mr. Lalio</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349216</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Giles, Mr. Frederick Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28134</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>863</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Swift, Mrs. Frederick Joel (Margaret Welles Ba...</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17466</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>D17</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>865</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Gill, Mr. John William</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>233866</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>866</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Bystrom, Mrs. (Karolina)</td>\n",
       "      <td>female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>236852</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>867</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Duran y More, Miss. Asuncion</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/PARIS 2149</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>868</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Roebling, Mr. Washington Augustus II</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17590</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>A24</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>van Melkebeke, Mr. Philemon</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345777</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>870</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Master. Harold Theodor</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>871</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Balkic, Mr. Cerin</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349248</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D35</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>873</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Carlsson, Mr. Frans Olof</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Cruyssen, Mr. Victor</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345765</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Abelson, Mrs. Samuel (Hannah Wizosky)</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>P/PP 3381</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>876</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Najib, Miss. Adele Kiamie \"Jane\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2667</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>877</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Gustafsson, Mr. Alfred Ossian</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7534</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>878</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Petroff, Mr. Nedelio</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349212</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>879</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Laleff, Mr. Kristo</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349217</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)</td>\n",
       "      <td>female</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11767</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C50</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>881</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Shelley, Mrs. William (Imanita Parrish Hall)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>230433</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Markun, Mr. Johann</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349257</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>883</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dahlberg, Miss. Gerda Ulrika</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7552</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>884</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Banfield, Mr. Frederick James</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A./SOTON 34068</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sutehall, Mr. Henry Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392076</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Mrs. William (Margaret Norton)</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "5              6         0       3   \n",
       "6              7         0       1   \n",
       "7              8         0       3   \n",
       "8              9         1       3   \n",
       "9             10         1       2   \n",
       "10            11         1       3   \n",
       "11            12         1       1   \n",
       "12            13         0       3   \n",
       "13            14         0       3   \n",
       "14            15         0       3   \n",
       "15            16         1       2   \n",
       "16            17         0       3   \n",
       "17            18         1       2   \n",
       "18            19         0       3   \n",
       "19            20         1       3   \n",
       "20            21         0       2   \n",
       "21            22         1       2   \n",
       "22            23         1       3   \n",
       "23            24         1       1   \n",
       "24            25         0       3   \n",
       "25            26         1       3   \n",
       "26            27         0       3   \n",
       "27            28         0       1   \n",
       "28            29         1       3   \n",
       "29            30         0       3   \n",
       "..           ...       ...     ...   \n",
       "861          862         0       2   \n",
       "862          863         1       1   \n",
       "863          864         0       3   \n",
       "864          865         0       2   \n",
       "865          866         1       2   \n",
       "866          867         1       2   \n",
       "867          868         0       1   \n",
       "868          869         0       3   \n",
       "869          870         1       3   \n",
       "870          871         0       3   \n",
       "871          872         1       1   \n",
       "872          873         0       1   \n",
       "873          874         0       3   \n",
       "874          875         1       2   \n",
       "875          876         1       3   \n",
       "876          877         0       3   \n",
       "877          878         0       3   \n",
       "878          879         0       3   \n",
       "879          880         1       1   \n",
       "880          881         1       2   \n",
       "881          882         0       3   \n",
       "882          883         0       3   \n",
       "883          884         0       2   \n",
       "884          885         0       3   \n",
       "885          886         0       3   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                     Moran, Mr. James    male   NaN      0   \n",
       "6                              McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                       Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                  Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "10                     Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                            Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "12                      Saundercock, Mr. William Henry    male  20.0      0   \n",
       "13                         Andersson, Mr. Anders Johan    male  39.0      1   \n",
       "14                Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
       "15                    Hewlett, Mrs. (Mary D Kingcome)   female  55.0      0   \n",
       "16                                Rice, Master. Eugene    male   2.0      4   \n",
       "17                        Williams, Mr. Charles Eugene    male   NaN      0   \n",
       "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
       "19                             Masselmani, Mrs. Fatima  female   NaN      0   \n",
       "20                                Fynney, Mr. Joseph J    male  35.0      0   \n",
       "21                               Beesley, Mr. Lawrence    male  34.0      0   \n",
       "22                         McGowan, Miss. Anna \"Annie\"  female  15.0      0   \n",
       "23                        Sloper, Mr. William Thompson    male  28.0      0   \n",
       "24                       Palsson, Miss. Torborg Danira  female   8.0      3   \n",
       "25   Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...  female  38.0      1   \n",
       "26                             Emir, Mr. Farred Chehab    male   NaN      0   \n",
       "27                      Fortune, Mr. Charles Alexander    male  19.0      3   \n",
       "28                       O'Dwyer, Miss. Ellen \"Nellie\"  female   NaN      0   \n",
       "29                                 Todoroff, Mr. Lalio    male   NaN      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "861                        Giles, Mr. Frederick Edward    male  21.0      1   \n",
       "862  Swift, Mrs. Frederick Joel (Margaret Welles Ba...  female  48.0      0   \n",
       "863                  Sage, Miss. Dorothy Edith \"Dolly\"  female   NaN      8   \n",
       "864                             Gill, Mr. John William    male  24.0      0   \n",
       "865                           Bystrom, Mrs. (Karolina)  female  42.0      0   \n",
       "866                       Duran y More, Miss. Asuncion  female  27.0      1   \n",
       "867               Roebling, Mr. Washington Augustus II    male  31.0      0   \n",
       "868                        van Melkebeke, Mr. Philemon    male   NaN      0   \n",
       "869                    Johnson, Master. Harold Theodor    male   4.0      1   \n",
       "870                                  Balkic, Mr. Cerin    male  26.0      0   \n",
       "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.0      1   \n",
       "872                           Carlsson, Mr. Frans Olof    male  33.0      0   \n",
       "873                        Vander Cruyssen, Mr. Victor    male  47.0      0   \n",
       "874              Abelson, Mrs. Samuel (Hannah Wizosky)  female  28.0      1   \n",
       "875                   Najib, Miss. Adele Kiamie \"Jane\"  female  15.0      0   \n",
       "876                      Gustafsson, Mr. Alfred Ossian    male  20.0      0   \n",
       "877                               Petroff, Mr. Nedelio    male  19.0      0   \n",
       "878                                 Laleff, Mr. Kristo    male   NaN      0   \n",
       "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n",
       "880       Shelley, Mrs. William (Imanita Parrish Hall)  female  25.0      0   \n",
       "881                                 Markun, Mr. Johann    male  33.0      0   \n",
       "882                       Dahlberg, Miss. Gerda Ulrika  female  22.0      0   \n",
       "883                      Banfield, Mr. Frederick James    male  28.0      0   \n",
       "884                             Sutehall, Mr. Henry Jr    male  25.0      0   \n",
       "885               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket      Fare        Cabin Embarked  \n",
       "0        0         A/5 21171    7.2500          NaN        S  \n",
       "1        0          PC 17599   71.2833          C85        C  \n",
       "2        0  STON/O2. 3101282    7.9250          NaN        S  \n",
       "3        0            113803   53.1000         C123        S  \n",
       "4        0            373450    8.0500          NaN        S  \n",
       "5        0            330877    8.4583          NaN        Q  \n",
       "6        0             17463   51.8625          E46        S  \n",
       "7        1            349909   21.0750          NaN        S  \n",
       "8        2            347742   11.1333          NaN        S  \n",
       "9        0            237736   30.0708          NaN        C  \n",
       "10       1           PP 9549   16.7000           G6        S  \n",
       "11       0            113783   26.5500         C103        S  \n",
       "12       0         A/5. 2151    8.0500          NaN        S  \n",
       "13       5            347082   31.2750          NaN        S  \n",
       "14       0            350406    7.8542          NaN        S  \n",
       "15       0            248706   16.0000          NaN        S  \n",
       "16       1            382652   29.1250          NaN        Q  \n",
       "17       0            244373   13.0000          NaN        S  \n",
       "18       0            345763   18.0000          NaN        S  \n",
       "19       0              2649    7.2250          NaN        C  \n",
       "20       0            239865   26.0000          NaN        S  \n",
       "21       0            248698   13.0000          D56        S  \n",
       "22       0            330923    8.0292          NaN        Q  \n",
       "23       0            113788   35.5000           A6        S  \n",
       "24       1            349909   21.0750          NaN        S  \n",
       "25       5            347077   31.3875          NaN        S  \n",
       "26       0              2631    7.2250          NaN        C  \n",
       "27       2             19950  263.0000  C23 C25 C27        S  \n",
       "28       0            330959    7.8792          NaN        Q  \n",
       "29       0            349216    7.8958          NaN        S  \n",
       "..     ...               ...       ...          ...      ...  \n",
       "861      0             28134   11.5000          NaN        S  \n",
       "862      0             17466   25.9292          D17        S  \n",
       "863      2          CA. 2343   69.5500          NaN        S  \n",
       "864      0            233866   13.0000          NaN        S  \n",
       "865      0            236852   13.0000          NaN        S  \n",
       "866      0     SC/PARIS 2149   13.8583          NaN        C  \n",
       "867      0          PC 17590   50.4958          A24        S  \n",
       "868      0            345777    9.5000          NaN        S  \n",
       "869      1            347742   11.1333          NaN        S  \n",
       "870      0            349248    7.8958          NaN        S  \n",
       "871      1             11751   52.5542          D35        S  \n",
       "872      0               695    5.0000  B51 B53 B55        S  \n",
       "873      0            345765    9.0000          NaN        S  \n",
       "874      0         P/PP 3381   24.0000          NaN        C  \n",
       "875      0              2667    7.2250          NaN        C  \n",
       "876      0              7534    9.8458          NaN        S  \n",
       "877      0            349212    7.8958          NaN        S  \n",
       "878      0            349217    7.8958          NaN        S  \n",
       "879      1             11767   83.1583          C50        C  \n",
       "880      1            230433   26.0000          NaN        S  \n",
       "881      0            349257    7.8958          NaN        S  \n",
       "882      0              7552   10.5167          NaN        S  \n",
       "883      0  C.A./SOTON 34068   10.5000          NaN        S  \n",
       "884      0   SOTON/OQ 392076    7.0500          NaN        S  \n",
       "885      5            382652   29.1250          NaN        Q  \n",
       "886      0            211536   13.0000          NaN        S  \n",
       "887      0            112053   30.0000          B42        S  \n",
       "888      2        W./C. 6607   23.4500          NaN        S  \n",
       "889      0            111369   30.0000         C148        C  \n",
       "890      0            370376    7.7500          NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')\n",
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Humblen, Mr. Adolf Mathias Nicolai Olsen</td>\n",
       "      <td>male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>348121</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>F G63</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ryerson, Miss. Emily Borie</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>PC 17608</td>\n",
       "      <td>262.3750</td>\n",
       "      <td>B57 B59 B63 B66</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>667</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Butler, Mr. Reginald Fenton</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>234686</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bateman, Rev. Robert James</td>\n",
       "      <td>male</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S.O.P. 1166</td>\n",
       "      <td>12.5250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>723</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Gillespie, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12233</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vanden Steen, Mr. Leo Peter</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345783</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Olsson, Mr. Nils Johan Goransson</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347464</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Strom, Miss. Telma Matilda</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>347054</td>\n",
       "      <td>10.4625</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Miss. Hildur E</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "699          700         0       3   \n",
       "311          312         1       1   \n",
       "666          667         0       2   \n",
       "150          151         0       2   \n",
       "18            19         0       3   \n",
       "722          723         0       2   \n",
       "355          356         0       3   \n",
       "281          282         0       3   \n",
       "205          206         0       3   \n",
       "479          480         1       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "699           Humblen, Mr. Adolf Mathias Nicolai Olsen    male  42.0      0   \n",
       "311                         Ryerson, Miss. Emily Borie  female  18.0      2   \n",
       "666                        Butler, Mr. Reginald Fenton    male  25.0      0   \n",
       "150                         Bateman, Rev. Robert James    male  51.0      0   \n",
       "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
       "722                       Gillespie, Mr. William Henry    male  34.0      0   \n",
       "355                        Vanden Steen, Mr. Leo Peter    male  28.0      0   \n",
       "281                   Olsson, Mr. Nils Johan Goransson    male  28.0      0   \n",
       "205                         Strom, Miss. Telma Matilda  female   2.0      0   \n",
       "479                           Hirvonen, Miss. Hildur E  female   2.0      0   \n",
       "\n",
       "     Parch       Ticket      Fare            Cabin Embarked  \n",
       "699      0       348121    7.6500            F G63        S  \n",
       "311      2     PC 17608  262.3750  B57 B59 B63 B66        C  \n",
       "666      0       234686   13.0000              NaN        S  \n",
       "150      0  S.O.P. 1166   12.5250              NaN        S  \n",
       "18       0       345763   18.0000              NaN        S  \n",
       "722      0        12233   13.0000              NaN        S  \n",
       "355      0       345783    9.5000              NaN        S  \n",
       "281      0       347464    7.8542              NaN        S  \n",
       "205      1       347054   10.4625               G6        S  \n",
       "479      1      3101298   12.2875              NaN        S  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理について記述せよ\n",
    "以下の観点をすべて含めて記述しましょう。\n",
    "\n",
    "・前処理とは何か  \n",
    "・なぜ前処理を行う必要があるのか  \n",
    "・前処理は具体的に何を行うか(3つ以上記述せよ)  \n",
    "・前述した具体的な前処理について、その前処理を行うと何を得ることができるか(記述したそれぞれの前処理例について記述せよ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答え：  \n",
    "・前処理とは、コンピュータが機械学習できるようにデータを加工処理すること。  \n",
    "・現実のデータは、空白（欠損値）や文字列や外れ値が入っていたりするため、コンピュータが数字で計算できるように、穴を埋めてあげたり文字を数字に置き換えたり誤ったデータを削除したりしなければならないから。　  \n",
    "・欠損値の削除・補完、文字列の数値変換、外れ値の検出と削除・置換  \n",
    "・欠損値の削除・補完は、欠損値による作業効率の低下（エラー）やデータ分析作業やデータ加工作業の複雑化や結果にバイアスが生じることの防止。文字列の数値変換は、文字列による作業効率の低下（エラー）やデータ分析作業やデータ加工作業の複雑化防止。外れ値による分析結果の歪みやモデルの過学習防止。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2/前処理について記述せよ\n",
    "前処理について記述せよの調査により、データを確認する際にどのような点を見るとよいか、3つ以上記述せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答え：  \n",
    "・各カラムの欠損値の有無及び頻度  \n",
    "・文字列カラムの有無と内容  \n",
    "・突出した値の有無及び頻度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Braund,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Cumings,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Heikkinen,</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Futrelle,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Allen,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex          Age  SibSp  Parch  \\\n",
       "0            1         0       3    male      Student      1      0   \n",
       "1            2         1       1  female        Adult      1      0   \n",
       "2            3         1       3  female  Young Adult      0      0   \n",
       "3            4         1       1  female  Young Adult      1      0   \n",
       "4            5         0       3    male  Young Adult      0      0   \n",
       "\n",
       "         Fare Cabin       Lname NamePrefix  \n",
       "0  1_quartile     N     Braund,        Mr.  \n",
       "1  4_quartile     C    Cumings,       Mrs.  \n",
       "2  1_quartile     N  Heikkinen,      Miss.  \n",
       "3  4_quartile     C   Futrelle,       Mrs.  \n",
       "4  2_quartile     N      Allen,        Mr.  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simplify_ages(df):\n",
    "    df.Age = df.Age.fillna(-0.5)\n",
    "    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n",
    "    group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "    categories = pd.cut(df.Age, bins, labels=group_names)\n",
    "    df.Age = categories\n",
    "    return df\n",
    "\n",
    "def simplify_cabins(df):\n",
    "    df.Cabin = df.Cabin.fillna('N')\n",
    "    df.Cabin = df.Cabin.apply(lambda x: x[0])\n",
    "    return df\n",
    "\n",
    "def simplify_fares(df):\n",
    "    df.Fare = df.Fare.fillna(-0.5)\n",
    "    bins = (-1, 0, 8, 15, 31, 1000)\n",
    "    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n",
    "    categories = pd.cut(df.Fare, bins, labels=group_names)\n",
    "    df.Fare = categories\n",
    "    return df\n",
    "\n",
    "def format_name(df):\n",
    "    df['Lname'] = df.Name.apply(lambda x: x.split(' ')[0])\n",
    "    df['NamePrefix'] = df.Name.apply(lambda x: x.split(' ')[1])\n",
    "    return df    \n",
    "\n",
    "def drop_features(df):\n",
    "    return df.drop(['Ticket', 'Name', 'Embarked'], axis=1)\n",
    "\n",
    "def transform_features(df):\n",
    "    df = simplify_ages(df)\n",
    "    df = simplify_cabins(df)\n",
    "    df = simplify_fares(df)\n",
    "    df = format_name(df)\n",
    "    df = drop_features(df)\n",
    "    return df\n",
    "\n",
    "data_train = transform_features(data_train)\n",
    "data_test = transform_features(data_test)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>329</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>267</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Cabin  Lname  \\\n",
       "0            1         0       3    1    4      1      0     0      7    100   \n",
       "1            2         1       1    0    0      1      0     3      2    182   \n",
       "2            3         1       3    0    7      0      0     0      7    329   \n",
       "3            4         1       1    0    7      1      0     3      2    267   \n",
       "4            5         0       3    1    7      0      0     1      7     15   \n",
       "\n",
       "   NamePrefix  \n",
       "0          19  \n",
       "1          20  \n",
       "2          16  \n",
       "3          20  \n",
       "4          19  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "def encode_features(df_train, df_test):\n",
    "    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']\n",
    "    df_combined = pd.concat([df_train[features], df_test[features]])\n",
    "\n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df_combined[feature])\n",
    "        df_train[feature] = le.transform(df_train[feature])\n",
    "        df_test[feature] = le.transform(df_test[feature])\n",
    "    return df_train, df_test\n",
    "\n",
    "data_train, data_test = encode_features(data_train, data_test)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理の内容について記述せよ\n",
    "以下の観点をすべて含めて記述しましょう。\n",
    "\n",
    "simplify_ages  \n",
    "simplify_cabins  \n",
    "simplify_fares  \n",
    "format_name  \n",
    "drop_features  \n",
    "encode_features  \n",
    "・以上のメソッドがそれぞれ何を行っているか記述せよ  \n",
    "・それぞれなぜそのようなことを行っているか記述せよ(それによって得られるメリットまで考察すること)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答え：  \n",
    "simplify_ages:欠損値を補充してカテゴライズ、欠損値を補充した部分はUnknownに分類。  \n",
    "年齢をカテゴライズすることでSurvivedとの関連性を把握しやすくするため、但し補充値に平均や中央値を入れてをそのまま使うと分析結果に歪みが出ることに配慮したもの。  \n",
    "simplify_cabins：欠損値に’N’を補充して、cabinsの等級（複数あるものは１つ）だけ残して番号を落とす（カテゴライズ）。  \n",
    "カテゴライズすることでSurvivedとの関連性を把握しやすくするため、但し補充値に平均や中央値を入れてをそのまま使うと分析結果に歪みが出ることに配慮したもの。  \n",
    "simplify_fares:欠損値を補充してカテゴライズ、欠損値を補充した部分はUnknownに分類。  \n",
    "カテゴライズすることでSurvivedとの関連性を把握しやすくするため、但し補充値に平均や中央値を入れてをそのまま使うと分析結果に歪みが出ることに配慮したもの。  \n",
    "format_name:nameを分割してラストネームと冠称に分ける。  \n",
    "Survivedと関係なさそうなname特徴量から関連性の有りそうな冠称部分を取り出して関連性を把握しやすくするため。  \n",
    "drop_features：関連性の薄い特徴量や不要になった特徴量を落とす。  \n",
    "精度を上げるため。  \n",
    "encode_features：カテゴリカルな特徴量を数値化。  \n",
    "関連性のあるカテゴリカルな特徴量を分類器にかけられるようにするため。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル選択について記述せよ\n",
    "今回使用するモデルは決定していますが、モデル選択をする際の演習を行いましょう。  \n",
    "・今回は、生存予測（分類）を行いますが、この分類について使用できそうな手法を4つ以上しらべて記述せよ。  \n",
    "・その手法の概要をそれぞれ記述せよ  \n",
    "・その手法の長所/短所をそれぞれ3つずつ、記述したすべての手法において記述せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答え：  \n",
    "ロジスティック回帰：2択の予測においてロジスティック曲線を使用して片方になる確率を0から1の値で算出する。回帰によって分類する手法。  \n",
    "長所は、訓練・予測が特に高速、特徴量の重要性・効果を説明し易い、多クラス分類にも対応、サンプル数が多くても少なくても性能を発揮。  \n",
    "短所は、精度が相対的に低い（特に低次元空間？）、精度が正則化パラメーターの調整に大きく左右される、係数の値の定や意味の理解が難しい。  \n",
    "サポートベクターマシーン(SVM)：データを分類するための境界線を決定する際に、境界線から一番近いサンプルデータまでのマージンの和が最大になる線を境界線とする手法。マージン最大化を取り入れることで少ないデータでも汎化性能が高い2分類回帰モデル。  \n",
    "長所は、訓練・予測が高速、特徴量の重要性・効果を説明し易い、サンプル数が多くても少なくても性能を発揮（大きい特徴セットに好適）。  \n",
    "短所は、精度が相対的に低い（特に低次元空間？）、２クラス分類のみに、対応精度が正則化パラメーターの調整に大きく左右される、係数の値の定や意味の理解が難しいこと。  \n",
    "決定木：木構造のモデルによって分類する手法。上から１つの説明変数とその閾値によってデータを２つに分け、さらに枝先で同様に別基準でデータを分けることによって、分類するモデル。  \n",
    "長所は、モデルが容易に可視化及び理解可能、データスケールに対して完全に不変（正規化や標準化の必要なし）、訓練・予測時間が比較的高速。  \n",
    "短所は、過剰適合しやすく汎化性能が低い、外挿ができないこと。  \n",
    "ランダムフォレスト：決定木を大量に生成し、各決定木の結果を集計して予測する手法。各決定木は独立しており、説明変数からのサンプリングまたは学習データからのサンプリングによって、異なる特性を持つように学習する。  \n",
    "長所は、非常に精度が高い、汎化性能も高い、特徴量の重要性・効果を説明し易い、パラメーターのチューニングがあまりいらいない、データのスケール変換不要。  \n",
    "短所は、予測過程の説明が決定木より可視化困難、多くのメモリ消費、訓練や予測に時間がかかる（但し、複数のCPUコアで簡単に並列可）、高次元で疎なデータに対してはうまく機能しないこと。  \n",
    "勾配ブースティング木：決定木を大量に生成し、各決定木の結果を集計して予測する手法。決定木を逐次的に増やしていき、生成済みの決定木が間違えてしまうケースのラベルを更新して、新たな決定木を生成していくイメージ。  \n",
    "長所は、非常に精度が高い、汎化性能も高い、特徴量のスケール変換の必要なし。  \n",
    "短所は、パラメータのチューニングに最新の注意が必要、訓練にかかる時間が長い、高次元の疎なデータに対してはうまく機能しないこと。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル選択の基準\n",
    "下記の参考資料を元に、どのような視点からモデルを選択すれば良いか、最低でも3つ以上の視点を記述すること(他の参考資料でも構わない、その場合参考資料を明記すること)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答え：\n",
    "精度、トレーニング時間、線形性、パラメーターの数、特徴の数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル選択におけるデータ可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>329</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>267</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>538</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>608</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>382</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>559</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>707</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>709</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>818</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>336</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>664</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>847</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>814</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>494</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>268</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>509</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>744</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>608</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>237</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>257</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>587</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>794</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>281</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>863</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>782</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>700</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>865</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>283</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>866</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>114</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>867</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>227</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>868</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>676</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>867</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>870</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>382</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>871</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>873</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>814</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>876</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>554</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>877</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>301</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>878</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>638</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>879</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>422</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>650</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>881</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>722</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>492</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>883</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>186</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>884</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>777</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>664</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>535</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>383</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>214</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Cabin  \\\n",
       "0              1         0       3    1    4      1      0     0      7   \n",
       "1              2         1       1    0    0      1      0     3      2   \n",
       "2              3         1       3    0    7      0      0     0      7   \n",
       "3              4         1       1    0    7      1      0     3      2   \n",
       "4              5         0       3    1    7      0      0     1      7   \n",
       "5              6         0       3    1    6      0      0     1      7   \n",
       "6              7         0       1    1    0      0      0     3      4   \n",
       "7              8         0       3    1    1      3      1     2      7   \n",
       "8              9         1       3    0    7      0      2     1      7   \n",
       "9             10         1       2    0    5      1      0     2      7   \n",
       "10            11         1       3    0    1      1      1     2      6   \n",
       "11            12         1       1    0    0      0      0     2      2   \n",
       "12            13         0       3    1    4      0      0     1      7   \n",
       "13            14         0       3    1    0      1      5     3      7   \n",
       "14            15         0       3    0    5      0      0     0      7   \n",
       "15            16         1       2    0    0      0      0     2      7   \n",
       "16            17         0       3    1    1      4      1     2      7   \n",
       "17            18         1       2    1    6      0      0     1      7   \n",
       "18            19         0       3    0    7      1      0     2      7   \n",
       "19            20         1       3    0    6      0      0     0      7   \n",
       "20            21         0       2    1    7      0      0     2      7   \n",
       "21            22         1       2    1    7      0      0     1      3   \n",
       "22            23         1       3    0    5      0      0     1      7   \n",
       "23            24         1       1    1    7      0      0     3      0   \n",
       "24            25         0       3    0    2      3      1     2      7   \n",
       "25            26         1       3    0    0      1      5     3      7   \n",
       "26            27         0       3    1    6      0      0     0      7   \n",
       "27            28         0       1    1    4      3      2     3      2   \n",
       "28            29         1       3    0    6      0      0     0      7   \n",
       "29            30         0       3    1    6      0      0     0      7   \n",
       "..           ...       ...     ...  ...  ...    ...    ...   ...    ...   \n",
       "861          862         0       2    1    4      1      0     1      7   \n",
       "862          863         1       1    0    0      0      0     2      3   \n",
       "863          864         0       3    0    6      8      2     3      7   \n",
       "864          865         0       2    1    4      0      0     1      7   \n",
       "865          866         1       2    0    0      0      0     1      7   \n",
       "866          867         1       2    0    7      1      0     1      7   \n",
       "867          868         0       1    1    7      0      0     3      0   \n",
       "868          869         0       3    1    6      0      0     1      7   \n",
       "869          870         1       3    1    1      1      1     1      7   \n",
       "870          871         0       3    1    7      0      0     0      7   \n",
       "871          872         1       1    0    0      1      1     3      3   \n",
       "872          873         0       1    1    7      0      0     0      1   \n",
       "873          874         0       3    1    0      0      0     1      7   \n",
       "874          875         1       2    0    7      1      0     2      7   \n",
       "875          876         1       3    0    5      0      0     0      7   \n",
       "876          877         0       3    1    4      0      0     1      7   \n",
       "877          878         0       3    1    4      0      0     0      7   \n",
       "878          879         0       3    1    6      0      0     0      7   \n",
       "879          880         1       1    0    0      0      1     3      2   \n",
       "880          881         1       2    0    4      0      1     2      7   \n",
       "881          882         0       3    1    7      0      0     0      7   \n",
       "882          883         0       3    0    4      0      0     1      7   \n",
       "883          884         0       2    1    7      0      0     1      7   \n",
       "884          885         0       3    1    4      0      0     0      7   \n",
       "885          886         0       3    0    0      0      5     2      7   \n",
       "886          887         0       2    1    7      0      0     1      7   \n",
       "887          888         1       1    0    4      0      0     2      1   \n",
       "888          889         0       3    0    6      1      2     2      7   \n",
       "889          890         1       1    1    7      0      0     2      2   \n",
       "890          891         0       3    1    7      0      0     0      7   \n",
       "\n",
       "     Lname  NamePrefix  \n",
       "0      100          19  \n",
       "1      182          20  \n",
       "2      329          16  \n",
       "3      267          20  \n",
       "4       15          19  \n",
       "5      538          19  \n",
       "6      500          19  \n",
       "7      608          13  \n",
       "8      382          20  \n",
       "9      559          20  \n",
       "10     707          16  \n",
       "11      86          16  \n",
       "12     709          19  \n",
       "13      21          19  \n",
       "14     818          16  \n",
       "15     336          20  \n",
       "16     664          13  \n",
       "17     847          19  \n",
       "18     814          25  \n",
       "19     494          20  \n",
       "20     268          19  \n",
       "21      68          19  \n",
       "22     509          16  \n",
       "23     744          19  \n",
       "24     608          16  \n",
       "25      33          20  \n",
       "26     237          19  \n",
       "27     257          19  \n",
       "28     587          16  \n",
       "29     794          19  \n",
       "..     ...         ...  \n",
       "861    281          19  \n",
       "862    782          20  \n",
       "863    700          16  \n",
       "864    283          19  \n",
       "865    114          20  \n",
       "866    227          33  \n",
       "867    676          19  \n",
       "868    867          14  \n",
       "869    382          13  \n",
       "870     49          19  \n",
       "871     67          20  \n",
       "872    128          19  \n",
       "873    814           5  \n",
       "874      3          20  \n",
       "875    554          16  \n",
       "876    301          19  \n",
       "877    638          19  \n",
       "878    422          19  \n",
       "879    650          20  \n",
       "880    722          20  \n",
       "881    492          19  \n",
       "882    186          16  \n",
       "883     51          19  \n",
       "884    777          19  \n",
       "885    664          20  \n",
       "886    535          26  \n",
       "887    294          16  \n",
       "888    383          16  \n",
       "889     69          19  \n",
       "890    214          19  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEFCAYAAADqujDUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFAAiIin1/2xnbmGDXfKYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114d51048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=\"Age\", y=\"Survived\", hue=\"Sex\", data=data_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEFCAYAAADqujDUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114bff7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pointplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=data_train,\n",
    "              palette={1: \"blue\", 0: \"pink\"},\n",
    "              markers=[\"*\", \"o\"], linestyles=[\"-\", \"--\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの可視化の結果について考察せよ\n",
    "・上記の２つの可視化から分かったことについて考察せよ。  \n",
    "・上記の考察結果から、モデル選択を考える場合、どのようなことが考えられるか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答え：  \n",
    "女性は男性に比べて生存率が高い、男性であっても幼児や子供は生存率が高い、女性は子供だけ生存率が低い（？）、Pclassが１の人は生存率が高く３の人は生存率が低くなる、Pclass2の場合、女性であれば（１に近い）高い生存率だが男性だと（３に近い）低い生存率となる。  \n",
    "線形分類には馴染みにくそう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data_train.drop(['Survived', 'PassengerId'], axis=1)\n",
    "y = data_train['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ランダムフォレストについて記述せよ  \n",
    "以下の観点をすべて含めて記述しましょう。  \n",
    "・決定木とはどのような手法か  \n",
    "・ランダムフォレストとはどのような手法か  \n",
    "・ランダムフォレストの長所と短所をそれぞれ3つ以上挙げてください。  \n",
    "・今回の目的からランダムフォレストの手法が適する理由を考察し、記述せよ  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答え：  \n",
    "決定木：木構造のモデルによって分類する手法。上から１つの説明変数とその閾値によってデータを２つに分け、さらに枝先で同様に別基準でデータを分けることによって、分類するモデル。  \n",
    "ランダムフォレスト：決定木を大量に生成し、各決定木の結果を集計して予測する手法。各決定木は独立しており、説明変数からのサンプリングまたは学習データからのサンプリングによって、異なる特性を持つように学習する。  \n",
    "長所は、非常に精度が高い、汎化性能も高い、特徴量の重要性・効果を説明し易い、パラメーターのチューニングがあまりいらいない、データのスケール変換不要。  \n",
    "短所は、予測過程の説明が決定木よりは可視化困難、多くのメモリ消費、訓練や予測に時間がかかる（但し、複数のCPUコアで簡単に並列可）、高次元で疎なデータに対してはうまく機能しないこと。  \n",
    "ランダムフォレストの手法が適する理由としては、データ可視化による分析結果からすると線形分類には馴染みにくそうであること、決定木と比べて精度及び汎化性能が高いこと"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97191011236\n",
      "0.787709497207\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=15,random_state=0).fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 精度を高める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818820224719\n",
      "0.826815642458\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=3,criterion='entropy',random_state=0).fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパーパラメータについて  \n",
    "・ハイパーパラメーターとは何か  \n",
    "・ランダムフォレストにおいてどのようなハイパーパラメーターがあるか4つ以上記述せよ  \n",
    "・記述したハイパーパラメーターにおいて、それぞれどのような値が存在するか記述せよ（そのハイパーパラメーターを変化させるとどのようなことが起きるかも記述すること）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答え：  \n",
    "ハイパーパラメータとは、事前確率を決めるパラメータや確率モデル全体に影響を与えるパラメータのことで、ハイパーパラメータを決定（調整）することによって確率モデルの精度や汎化能力が決定（左右）する。  \n",
    "ランダムフォレストの代表的なハイパーパラメーターは、  \n",
    "n_estimators:整数を指定．デフォルトの値は10．バギングに用いる決定木の個数を指定．\n",
    "criterion:文字列を指定．デフォルトは gini．その他に entropy を指定できる．決定木はこの指標を基準にデータを分割する．  \n",
    "max_features:整数，小数，文字列または None を指定．デフォルトは None．最適な分割をするために考慮するフィーチャーの数を指定．整数を指定した場合，その個数，小数の場合全フィーチャーに対する割合個，auto を指定した場合，フィーチャー数のルート個，log2 を指定した場合，log2(フィーチャー数) 個．    \n",
    "max_depth:整数または None を指定．決定木の深さの最大値を指定．過学習を避けるためにはこれを調節するのが最も重要．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検証について記述せよ  \n",
    "・検証は何か  \n",
    "・なぜ検証を行う必要があるのか(Accuracyだけではダメな理由も含めること)  \n",
    "・主な検証方法について2つ以上記述せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：  \n",
    "検証とは機械学習モデルの有効性を確認する工程で、UnderFittingやOverFitting（特にOverFitting）が起こっていないかを確認してモデルに汎用性があるか判明させるために必要。  \n",
    "検証方法としては、ホールドアウト方、K分割交差検証などがある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFoldについて記述せよ  \n",
    "・K-分割交差検証について説明せよ  \n",
    "・K-分割交差検証はデータセットを何個に分割するか  \n",
    "・データセットを分割する際、その個数はどのように考えると良いか  \n",
    "・K-分割交差検証は何回の検証を行うか  \n",
    "・K-分割交差検証の結果は、最終的にどのように求められるか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：  \n",
    "K-分割交差検証とは、正解付きのデータをK分割して，そのうち1つをテストデータに，残りのK-1個を訓練データとして学習と精度の評価を行い、これをK個のデータのかたまりに渡って順に，つまり学習と評価をK回行って，その結果を平均したものを「未知のデータへの対応能力」とする方法です。  \n",
    "k の値は大きければ大きいほど、正確にモデルを評価できます。サンプル数に対して k が小さすぎると、正答率の誤差が大きくなります（k の最大値はサンプル数ですので、「k = サンプル数」とした場合が最も正確な評価だと言えます）。しかし、k が大きければそれだけ実行に時間がかかるので、k は正答率の誤差が大きくならない範囲でなるべく小さい値にしなければなりません（http://d.hatena.ne.jp/hoxo_m/20110618/p1　ではk = (1 + log(n)/log(2)) * 4が減少率の境目かなーと書かれていました）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFoldの実施・結果確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811447811448\n",
      "0.79797979798\n",
      "0.79797979798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noritakeriu/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/ipykernel/__main__.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/noritakeriu/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/ipykernel/__main__.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/noritakeriu/.pyenv/versions/anaconda3-4.3.0/lib/python3.6/site-packages/ipykernel/__main__.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.80246913580246915"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "X=X.loc[:,['Pclass','Sex','Age','SibSp','Parch','Fare','Cabin','Lname','NamePrefix']].values\n",
    "y=data_train.loc[:,['Survived']].values\n",
    "\n",
    "scores=0\n",
    "kf = KFold(n_splits=3,shuffle=True)\n",
    "for train, test in kf.split(X):\n",
    "#     print(train,test)\n",
    "    X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
    "    clf = RandomForestClassifier(max_depth=3,criterion='entropy',random_state=0).fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(score)\n",
    "    scores += score\n",
    "scores/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## チューニング&検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [4, 6, 9], 'max_features': ['log2', 'sqrt', 'auto'], 'criterion': ['entropy', 'gini'], 'max_depth': [2, 3, 5, 10], 'min_samples_split': [2, 3, 5], 'min_samples_leaf': [1, 5, 8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 必要なライブラリのインポート\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "# 動かすパラメータを明示的に表示、今回は決定木の数を変えてみる\n",
    "params = {  'n_estimators': [4, 6, 9],\n",
    "            'max_features': ['log2', 'sqrt','auto'],\n",
    "            'criterion': ['entropy', 'gini'],\n",
    "            'max_depth': [2, 3, 5, 10],\n",
    "            'min_samples_split': [2, 3, 5],\n",
    "            'min_samples_leaf': [1,5,8]\n",
    "         }\n",
    "\n",
    "# モデルにインスタンス生成\n",
    "mod = RandomForestClassifier()\n",
    "\n",
    "# ハイパーパラメータ探索\n",
    "cv = GridSearchCV(estimator = mod, param_grid = params, cv = 10, scoring= 'accuracy', n_jobs = -1)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.78511, std: 0.04730, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.79635, std: 0.03521, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.79494, std: 0.04355, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.78933, std: 0.04059, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.79635, std: 0.03521, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.79775, std: 0.04773, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.77669, std: 0.06201, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.79213, std: 0.03944, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.79354, std: 0.03362, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79073, std: 0.03733, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.77949, std: 0.02752, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.79213, std: 0.04345, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80056, std: 0.05437, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.77669, std: 0.04586, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.78933, std: 0.04271, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.77669, std: 0.04269, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.79354, std: 0.04559, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.79354, std: 0.04528, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79073, std: 0.03264, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80337, std: 0.03342, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80618, std: 0.02485, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.76264, std: 0.03598, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.78090, std: 0.04174, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.78230, std: 0.03571, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.77528, std: 0.05847, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.77528, std: 0.05017, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.78652, std: 0.03949, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79916, std: 0.03678, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.78090, std: 0.05126, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.79213, std: 0.03399, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.77107, std: 0.04237, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.78090, std: 0.03710, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.78511, std: 0.03571, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.77247, std: 0.03414, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.77949, std: 0.05371, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81180, std: 0.04390, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.77528, std: 0.04447, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80337, std: 0.04325, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80197, std: 0.03932, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.78090, std: 0.05917, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80056, std: 0.03766, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.78371, std: 0.05427, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.80056, std: 0.04625, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.78371, std: 0.02780, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.79213, std: 0.04292, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.77247, std: 0.02539, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.77107, std: 0.04094, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.79073, std: 0.04016, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.78230, std: 0.04189, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.78933, std: 0.02804, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.79635, std: 0.02876, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.78371, std: 0.04221, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.78792, std: 0.03045, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.79494, std: 0.03647, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79635, std: 0.04622, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.78511, std: 0.05025, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.78792, std: 0.02921, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.77669, std: 0.03549, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.77669, std: 0.05918, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.78933, std: 0.04550, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.76826, std: 0.05999, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.78933, std: 0.03862, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.77949, std: 0.03588, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.77247, std: 0.04894, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.79213, std: 0.04148, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.78511, std: 0.03728, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.76124, std: 0.03016, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.76124, std: 0.04430, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.78371, std: 0.03943, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.79494, std: 0.04652, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.78230, std: 0.04129, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.77669, std: 0.03065, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.77247, std: 0.05477, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.76685, std: 0.03542, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.79494, std: 0.05804, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.74860, std: 0.05860, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.77949, std: 0.03952, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.79073, std: 0.04212, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.78230, std: 0.03784, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.78933, std: 0.03723, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.79775, std: 0.03905, params: {'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.81180, std: 0.04134, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80337, std: 0.03000, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.79775, std: 0.04989, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.78230, std: 0.05316, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81180, std: 0.03923, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.80056, std: 0.04646, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.80478, std: 0.05348, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80337, std: 0.04106, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.80478, std: 0.04806, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79775, std: 0.03191, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80899, std: 0.02819, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80197, std: 0.02482, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.78792, std: 0.04393, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80758, std: 0.04430, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.79775, std: 0.04687, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.79494, std: 0.03691, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.79354, std: 0.04522, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.79213, std: 0.03304, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80618, std: 0.03744, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80337, std: 0.03125, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.79916, std: 0.03776, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80618, std: 0.04645, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.78792, std: 0.04366, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.79775, std: 0.03354, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81180, std: 0.04415, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80899, std: 0.04040, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.80899, std: 0.03291, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.81461, std: 0.04239, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.79916, std: 0.04854, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81601, std: 0.03884, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80758, std: 0.03969, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81601, std: 0.03063, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.78652, std: 0.03377, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.80056, std: 0.04092, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.79354, std: 0.02654, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.80337, std: 0.03799, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79775, std: 0.04400, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.79635, std: 0.03495, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80618, std: 0.02866, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.78652, std: 0.03324, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.79494, std: 0.04370, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.80618, std: 0.03908, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81742, std: 0.05659, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80618, std: 0.02776, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.80758, std: 0.03447, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.78230, std: 0.04468, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80758, std: 0.04055, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80618, std: 0.04279, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.79354, std: 0.03934, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.79635, std: 0.04275, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.80197, std: 0.03994, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.78652, std: 0.05778, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.79073, std: 0.04605, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.80899, std: 0.04642, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80337, std: 0.04234, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81180, std: 0.02965, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.79354, std: 0.03348, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.81320, std: 0.02310, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.78933, std: 0.04150, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.79775, std: 0.04127, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.80197, std: 0.03371, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80056, std: 0.03841, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.82303, std: 0.03710, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.78792, std: 0.05187, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80478, std: 0.03587, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.79916, std: 0.03634, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80758, std: 0.03445, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80478, std: 0.04492, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.79494, std: 0.04031, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.80899, std: 0.03607, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80618, std: 0.04205, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.80478, std: 0.04946, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80758, std: 0.04095, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81320, std: 0.03824, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80899, std: 0.02961, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80899, std: 0.05579, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80478, std: 0.04743, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.81320, std: 0.02786, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.78652, std: 0.03835, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.81742, std: 0.03567, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.82022, std: 0.02915, params: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.81742, std: 0.03594, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81882, std: 0.05010, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80899, std: 0.03740, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.81039, std: 0.03886, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80618, std: 0.02584, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.81742, std: 0.04151, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81461, std: 0.03523, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.82303, std: 0.02796, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81461, std: 0.04326, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.81461, std: 0.03882, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81882, std: 0.03524, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.82303, std: 0.03173, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80899, std: 0.03419, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81461, std: 0.04264, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.82444, std: 0.03446, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.82022, std: 0.04497, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80478, std: 0.04487, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.82022, std: 0.04011, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.81601, std: 0.05061, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81461, std: 0.03672, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81742, std: 0.03361, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.81039, std: 0.04005, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81742, std: 0.03754, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.82022, std: 0.03722, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.80899, std: 0.02844, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.82163, std: 0.04153, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81320, std: 0.03737, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80618, std: 0.02704, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.82725, std: 0.03016, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.82444, std: 0.03070, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.82725, std: 0.03807, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80478, std: 0.02695, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.82584, std: 0.03716, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81039, std: 0.04031, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80758, std: 0.04220, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.82022, std: 0.03060, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.82022, std: 0.03166, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.82584, std: 0.04081, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81039, std: 0.04101, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.81882, std: 0.03922, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.82022, std: 0.03878, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.82303, std: 0.03749, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81742, std: 0.05466, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80337, std: 0.03397, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81461, std: 0.04673, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80758, std: 0.04906, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81461, std: 0.03909, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81601, std: 0.04530, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80758, std: 0.04427, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81461, std: 0.04055, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.80478, std: 0.04148, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.80337, std: 0.04017, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.82303, std: 0.03370, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.82163, std: 0.04230, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80899, std: 0.03911, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.82303, std: 0.04410, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81180, std: 0.03248, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.81320, std: 0.03808, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81039, std: 0.03577, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.80899, std: 0.03331, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81742, std: 0.03700, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.82163, std: 0.03366, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81039, std: 0.04115, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80197, std: 0.04823, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81882, std: 0.03794, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81180, std: 0.02714, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80899, std: 0.04932, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.82584, std: 0.03882, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.82725, std: 0.03854, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.80056, std: 0.04819, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.82163, std: 0.04173, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.82584, std: 0.04073, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.81742, std: 0.03170, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80056, std: 0.02580, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80618, std: 0.03899, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.79354, std: 0.03665, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.79916, std: 0.04201, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.80758, std: 0.03120, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81461, std: 0.03323, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80758, std: 0.03452, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.82303, std: 0.03413, params: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80337, std: 0.02142, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80899, std: 0.01864, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81461, std: 0.04058, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80618, std: 0.01220, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.82444, std: 0.02792, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.80899, std: 0.01676, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.79213, std: 0.03363, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.81039, std: 0.03150, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81461, std: 0.04363, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.81461, std: 0.04548, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80337, std: 0.03805, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80618, std: 0.04176, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.81320, std: 0.04489, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80197, std: 0.04280, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.81461, std: 0.04308, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81039, std: 0.03676, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.81180, std: 0.03229, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.82444, std: 0.04143, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79494, std: 0.04183, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81320, std: 0.03714, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81039, std: 0.04251, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.79916, std: 0.05585, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81320, std: 0.03714, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.82584, std: 0.03799, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.80899, std: 0.04443, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.82022, std: 0.03966, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.82725, std: 0.03798, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79916, std: 0.02651, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.83146, std: 0.03731, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81882, std: 0.03791, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.81039, std: 0.02659, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80337, std: 0.02327, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.80337, std: 0.03892, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81601, std: 0.03029, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.82725, std: 0.03782, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81882, std: 0.03490, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.81742, std: 0.03793, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.79494, std: 0.03737, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.83006, std: 0.03387, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80618, std: 0.04242, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.82444, std: 0.03845, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.81742, std: 0.03611, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.82303, std: 0.05182, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.81601, std: 0.03805, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81742, std: 0.02749, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80197, std: 0.03300, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81180, std: 0.04149, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81882, std: 0.03724, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.83146, std: 0.03582, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81461, std: 0.05012, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.81180, std: 0.03899, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81180, std: 0.02994, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.81882, std: 0.04060, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.83006, std: 0.03240, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79213, std: 0.05122, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80056, std: 0.03521, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81320, std: 0.03021, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.79916, std: 0.03473, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.82444, std: 0.02942, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.82303, std: 0.02309, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.80478, std: 0.03268, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80618, std: 0.02680, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.82444, std: 0.02776, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.81039, std: 0.03941, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81461, std: 0.04861, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.82163, std: 0.04924, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.82163, std: 0.03405, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81180, std: 0.03667, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.82725, std: 0.04270, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81180, std: 0.03669, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.81461, std: 0.03474, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81461, std: 0.03928, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80197, std: 0.04297, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81742, std: 0.04113, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.82725, std: 0.04637, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.81882, std: 0.03919, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80478, std: 0.03995, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.82022, std: 0.04261, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81180, std: 0.04246, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.82163, std: 0.03566, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81180, std: 0.03659, params: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.75562, std: 0.05180, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.79073, std: 0.03791, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.78652, std: 0.04576, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.81039, std: 0.03904, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.78090, std: 0.04223, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.78792, std: 0.02884, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.78933, std: 0.04731, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.79073, std: 0.03625, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.78371, std: 0.04205, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79213, std: 0.02651, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.78652, std: 0.04243, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80056, std: 0.04883, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.76966, std: 0.05105, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.79494, std: 0.04404, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.78933, std: 0.03218, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.76545, std: 0.05266, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.79635, std: 0.03628, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.78652, std: 0.04492, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.77107, std: 0.03423, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.79775, std: 0.03739, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.78371, std: 0.03767, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.76966, std: 0.06078, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.77809, std: 0.04027, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.77107, std: 0.04411, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.76685, std: 0.05892, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.78652, std: 0.03492, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.78933, std: 0.04811, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.78792, std: 0.04128, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.78230, std: 0.04438, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.79213, std: 0.04733, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.78090, std: 0.04665, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.77809, std: 0.06356, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.79213, std: 0.04398, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.76966, std: 0.04108, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.77388, std: 0.04064, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.78933, std: 0.03507, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.77528, std: 0.04743, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.77528, std: 0.04984, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.77669, std: 0.04592, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.77247, std: 0.04272, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.77528, std: 0.03767, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.79213, std: 0.04210, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.76685, std: 0.03290, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.79494, std: 0.05120, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.78792, std: 0.03933, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.77247, std: 0.06525, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.78230, std: 0.03305, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.78511, std: 0.05517, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.76966, std: 0.03926, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.78792, std: 0.06133, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.78371, std: 0.04266, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.78933, std: 0.04360, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.79354, std: 0.04404, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.78652, std: 0.03304, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.77669, std: 0.03845, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.79775, std: 0.04164, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.79775, std: 0.03663, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.76124, std: 0.04576, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.79073, std: 0.04787, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.78652, std: 0.04447, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.79213, std: 0.05086, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.79916, std: 0.03755, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81180, std: 0.04494, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79213, std: 0.04687, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.78230, std: 0.05242, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.79073, std: 0.03880, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.79916, std: 0.04675, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.78371, std: 0.03275, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.79073, std: 0.03689, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.75421, std: 0.05001, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80337, std: 0.03767, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.76966, std: 0.03125, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79073, std: 0.05329, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.79635, std: 0.04091, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.78511, std: 0.03525, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.77528, std: 0.05485, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.77388, std: 0.03981, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.79635, std: 0.03793, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.77247, std: 0.06380, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.77388, std: 0.05744, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.79775, std: 0.04544, params: {'criterion': 'gini', 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80197, std: 0.04475, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81180, std: 0.04293, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80758, std: 0.04409, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.78652, std: 0.02905, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.79635, std: 0.03965, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.80758, std: 0.04104, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.79635, std: 0.04240, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80618, std: 0.04991, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.80337, std: 0.04712, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.78933, std: 0.04540, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.79775, std: 0.03091, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80056, std: 0.03444, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.79775, std: 0.04470, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80899, std: 0.03120, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.81180, std: 0.04796, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81180, std: 0.04827, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80056, std: 0.03012, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.80478, std: 0.03641, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79354, std: 0.03005, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.79354, std: 0.03735, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80899, std: 0.03566, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.79916, std: 0.04539, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80618, std: 0.03067, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.80056, std: 0.04196, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.79916, std: 0.05268, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.79775, std: 0.03448, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81180, std: 0.04707, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.78652, std: 0.05556, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80197, std: 0.03525, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80618, std: 0.03878, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.79213, std: 0.04473, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80478, std: 0.03923, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.80337, std: 0.04037, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.79635, std: 0.03564, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80197, std: 0.02666, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.79635, std: 0.02753, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79775, std: 0.02129, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80899, std: 0.02612, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80618, std: 0.04879, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.78371, std: 0.04117, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.79775, std: 0.04100, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.80899, std: 0.03402, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.79494, std: 0.03971, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.81180, std: 0.04279, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81601, std: 0.04057, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80758, std: 0.04065, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80758, std: 0.04600, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80337, std: 0.03095, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80758, std: 0.04111, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80337, std: 0.04608, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.80618, std: 0.03704, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.79073, std: 0.03745, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80899, std: 0.04238, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81180, std: 0.04415, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.78371, std: 0.04870, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.79916, std: 0.03111, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80899, std: 0.03792, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.77949, std: 0.03944, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80618, std: 0.02832, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.80197, std: 0.03879, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.79775, std: 0.02727, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80478, std: 0.03954, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81039, std: 0.03781, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80337, std: 0.03936, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81180, std: 0.03390, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80478, std: 0.03519, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80056, std: 0.04750, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80478, std: 0.03992, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.81039, std: 0.04541, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.80618, std: 0.04318, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.78933, std: 0.04279, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81320, std: 0.04386, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80618, std: 0.02815, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80197, std: 0.03639, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80478, std: 0.02914, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80337, std: 0.04400, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80899, std: 0.05335, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.80197, std: 0.04236, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81461, std: 0.03796, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.81039, std: 0.04491, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.79916, std: 0.03458, params: {'criterion': 'gini', 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80197, std: 0.03355, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81039, std: 0.03001, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81039, std: 0.04420, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80899, std: 0.05593, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81461, std: 0.02826, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.81601, std: 0.03575, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.80337, std: 0.02961, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.81039, std: 0.02507, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81601, std: 0.05215, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.82444, std: 0.03229, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81039, std: 0.04668, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.82303, std: 0.03179, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.82444, std: 0.03229, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81320, std: 0.04734, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.81180, std: 0.05792, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81180, std: 0.04437, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80899, std: 0.04142, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81882, std: 0.03197, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80056, std: 0.04107, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80758, std: 0.04350, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81180, std: 0.04490, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.81180, std: 0.02684, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81742, std: 0.03386, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.82163, std: 0.03690, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.82163, std: 0.04043, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80197, std: 0.04225, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.82022, std: 0.03817, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80758, std: 0.03508, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81039, std: 0.03913, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81882, std: 0.03771, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.81180, std: 0.03299, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81320, std: 0.04317, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.82725, std: 0.03763, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.80899, std: 0.04539, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.82444, std: 0.03419, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81601, std: 0.03275, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.81180, std: 0.03189, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80618, std: 0.03338, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81039, std: 0.03356, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.79635, std: 0.04162, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81039, std: 0.03912, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.81320, std: 0.02830, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81320, std: 0.03137, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.81742, std: 0.04416, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81320, std: 0.03111, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80337, std: 0.02729, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80758, std: 0.03944, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81180, std: 0.03535, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.79775, std: 0.02910, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81461, std: 0.03913, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.81742, std: 0.03311, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.79073, std: 0.05366, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.82865, std: 0.03697, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81882, std: 0.03441, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.81320, std: 0.02586, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80899, std: 0.03164, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81180, std: 0.03517, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.81882, std: 0.04187, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81882, std: 0.04439, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.82865, std: 0.03068, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.80337, std: 0.02632, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.81882, std: 0.02621, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.82303, std: 0.03214, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.81601, std: 0.02609, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.82163, std: 0.04054, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.80899, std: 0.03154, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.81461, std: 0.03668, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81742, std: 0.04582, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.81320, std: 0.04049, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81039, std: 0.03780, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.81742, std: 0.04528, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81882, std: 0.03817, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79916, std: 0.04733, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81882, std: 0.04683, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81320, std: 0.04657, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80758, std: 0.03874, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81461, std: 0.02541, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.82303, std: 0.03862, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.80618, std: 0.02668, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.81320, std: 0.03895, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81461, std: 0.03365, params: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79213, std: 0.02534, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.79635, std: 0.02319, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.79213, std: 0.03352, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.77809, std: 0.03345, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80618, std: 0.03923, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.82444, std: 0.02531, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81320, std: 0.02747, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.82022, std: 0.03537, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.82444, std: 0.03416, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79775, std: 0.05505, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81601, std: 0.04530, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.83006, std: 0.03753, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80758, std: 0.03903, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81461, std: 0.04538, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.82725, std: 0.04322, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.82444, std: 0.05344, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80197, std: 0.04927, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81180, std: 0.03582, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.81461, std: 0.05545, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80758, std: 0.04141, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81039, std: 0.03246, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80618, std: 0.03733, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.82022, std: 0.04304, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.82022, std: 0.03585, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81180, std: 0.04865, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80758, std: 0.04141, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81601, std: 0.04336, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79354, std: 0.02811, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80478, std: 0.03017, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81601, std: 0.03677, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80197, std: 0.02909, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80478, std: 0.03993, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.81882, std: 0.02303, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.79775, std: 0.03633, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80758, std: 0.02483, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.82022, std: 0.04318, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.82022, std: 0.03553, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.82022, std: 0.04484, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.82865, std: 0.04865, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.79775, std: 0.03796, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81039, std: 0.03060, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.81742, std: 0.03138, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.82022, std: 0.03491, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.81742, std: 0.05186, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.82303, std: 0.04109, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80899, std: 0.04455, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.82022, std: 0.03714, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81601, std: 0.03888, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.81320, std: 0.02695, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.82865, std: 0.04455, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.81461, std: 0.04836, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81742, std: 0.04172, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.82022, std: 0.03773, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.80758, std: 0.03831, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79213, std: 0.02481, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.81461, std: 0.02473, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81742, std: 0.04496, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.80618, std: 0.04098, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.80197, std: 0.02382, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.82022, std: 0.02734, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.79916, std: 0.03246, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.82725, std: 0.04046, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.82163, std: 0.03670, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.80478, std: 0.03276, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.80899, std: 0.03505, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.82865, std: 0.03496, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.81039, std: 0.03988, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.82303, std: 0.03928, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.81882, std: 0.03665, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.81742, std: 0.03664, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.80758, std: 0.04492, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.82163, std: 0.03237, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 9},\n",
       " mean: 0.79635, std: 0.03904, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 4},\n",
       " mean: 0.82865, std: 0.03147, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 6},\n",
       " mean: 0.81180, std: 0.04981, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 9},\n",
       " mean: 0.79775, std: 0.04921, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 4},\n",
       " mean: 0.81601, std: 0.03237, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 6},\n",
       " mean: 0.81601, std: 0.04326, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 3, 'n_estimators': 9},\n",
       " mean: 0.79775, std: 0.03195, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 4},\n",
       " mean: 0.82444, std: 0.04247, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 6},\n",
       " mean: 0.81882, std: 0.03718, params: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 5, 'n_estimators': 9}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## どの特徴量が重要であったかを調査する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x113ec85c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEjCAYAAAAv9opbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nz+h8bvYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113f474a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf.feature_importances_\n",
    "data = pd.Series(clf.feature_importances_, index=list(X.columns[:9]))\n",
    "data.plot(kind='bar', color = 'k', alpha=0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
